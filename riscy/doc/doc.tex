\documentclass{article}

\title{The Riscy Processor}
\author{Karan Bavishi, Mark Mansi, Suhas Pai, Preyas Shah}

\begin{document}

\maketitle

\section{Introduction}

We implement the RISCV ISA with a superscalar, out-of-order core. Our
implementation is optimized for correctness. Our second goal was performance.
Our third goal was synthesize-ability. All goals have been compromised for the
sake of completion.

\section{Overview}

\begin{itemize}
    \item 4-wide pipeline
    \item Out-of-order execution; In-order commit
    \item Fetch
        \begin{itemize}
            \item 3 cycle latency for cache hit (2 cycle I-cache latency)
            \item Branch prediction (TODO): 2-level predictor, BTB, global
                history register.
            \item I-Cache: Blocking, 4 KB, 2-way associative, 1 read/write port.
            \item Prefetch Buffer: 4 entries, 32 bytes each
        \end{itemize}
    \item Decode and Rename
        \begin{itemize}
            \item 64-entry ROB
            \item 2 cycle latency
        \end{itemize}
    \item Issue and FUs
        \begin{itemize}
            \item 4 ALUs
            \item 4 issue queues, 16 entries each, 1 ALU per queue
            \item Load-balancing arbiter places new instructions in issue
                queues.
            \item ALUs also used to compute \texttt{ld}/\texttt{st} addresses.
        \end{itemize}
    \item Address Queue
        \begin{itemize}
            \item 32 entries
            \item Tracks load/store dependencies.
            \item Non-speculative memory disambiguation.
            \item Loads access cache out-of-order between stores.
            \item Stores access cache on commit.
            \item D-Cache (TODO)
        \end{itemize}
    \item Writeback
        \begin{itemize}
            \item Processor supports back-to-back execution of dependent
                instructions.
            \item Writeback structure (a.k.a ROB WB or more affectionately,
                \texttt{FooPP}) is designed to avoid the massive tangle of wires
                created by broadcast-based writeback among 4 ALUs and a LSQ.
        \end{itemize}
    \item Stall: we implement a distinct top-level module to handle stall
        coordination among all stages. The two stall producers in the pipeline
        are the issue queue arbiter and the ROB. A stall is generated when there
        is not enough room in the issue queues or the ROB. Each stage is a
        consumer of stalls produced by stages before it.
\end{itemize}

\section{Modules}

Our processor has a pipeline depth of 8. The pipeline is divided into several
independently designed and implemented blocks (implemented as modules in
Chisel). This section presents an overview of the whole processor. Then, we
present the design of each block.

\subsection{Fetch}

Our fetch module encapsulates the logic of selecting the next PC, issuing
requests to the instruction memory hierarchy (including the I-cache), and presenting
instructions to the subsequent stage (decode).

We implement a pipelined, blocking, 2-way associative instruction cache with
2-cycle latency. And additional cycle of latency comes from computing the next
PC.

The instruction cache returns a hit if it finds the requested entry. If not, it
issues a refill request to memory for the missing address. Once the memory
responds, it refills its data and tag arrays with the response. The cache line
replacement policy is random replacement.  

We also added a prefetch buffer, containing 4 entries. It does cache block
prefetching ie. it stores the additional cache lines sent by memory as a part
of its response to a refill request. This is primarily done to get around the
single-port limitation of the I-cache. This prefetch buffer can be easily
changed to do next-line prefetching as a part of future work.

The output from the instruction cache is rotated and presented to the rest of
the pipeline.

\subsection{Decode and Allocate}

The next two cycles are consumed in decoding and renaming the instructions from
fetch.

Decode takes less than one cycle because it consists entirely of separating
wires. Thus, we combine decode with the first cycle of renaming.

Renaming proceeds in two phases. The first cycle decodes the instruction and
renames all destinations. The second cycle renames operands and produces and ROB
entry which can just be latched to the ROB next cycle.

\subsection{ROB}

The ROB is implemented as a 64-entry circular buffer. All committing logic is
implemented in the ROB module. 4 instructions can commit in a single cycle. In
the same cycle, 4 new ROB entries can also be added to the tail of the ROB.

We choose to use an ROB as opposed to a merged register file because we
prioritized performance and ease of implementation over energy.

\subsection{Issue and FUs}

In the same cycle, an ROB entry both latches in the ROB and goes to the issue
queue arbiter, which puts it in a queue. All instructions go through the arbiter
regardless of their type.

Our issue stage consists of an arbiter feeding 4 issue queues.
The arbiter does load balancing to attempt to keep any queue from becoming
filled while other ALUs are available.

Each issue queue is independent and feeds a single ALU. The issue queues can
each independently wake up a single instruction to be sent an ALU. Our
implementation is capable of speculatively waking up ALU operations when their
operands are known to be nearly ready. This allows our processor to execute
instruction with back-to-back dependencies. Our writeback mechanism helps with
this also...

\subsection{Writeback}

Each cycle, our processor may produce up to 6 values that need to be written
back (4 from ALUs and 2 from memory). To avoid creating $O(n^2)$ wires between
all of these value producers/consumers, we designed a single writeback
structure, which we call \texttt{FooPP}. All values are written back to the
\texttt{FooPP} in the cycle they produced. Any consumers of those values,
including the ROB and issue queues, take the values directly from the
\texttt{FooPP}.

To avoid adding a 1 cycle bubble between instructions with back-to-back
dependencies, the \texttt{FooPP} keeps 1 cycle of history, which the FUs can
then consume from easily.

The writeback structure also filters out any values coming from squashed
instructions. It does this by comparing the \emph{era} of the input values with
the \emph{current era} according to the ROB. This allows us to get rid of the
squashed instructions easily by letting them percolate through the pipeline.

\subsection{Address Queue}

When a load or store instruction reaches the arbiter, the arbiter asks the
address queue to reserve a spot for it. If the address queue is full, the
pipeline stalls. The arbiter then puts the load or store in a normal issue queue
to wait until an ALU can compute its address.

When the address is written to the \texttt{FooPP}, the address queue will
consume it.

Loads can access the D-cache as soon as their address is known and it is also
known that there is no preceding store to the same address.

Stores can access the D-cache as soon as the ROB signals the address queue that
they have committed.

To limit the number of ports need on the D-cache, we instead assume only two
ports. The ROB gives the guarantee that no more than 2 stores will commit in any
cycle.

\end{document}
